
## Model Training

Model training in this pipeline consists of a series of steps that prepares data, generates training labels, and trains a model. Below are the required steps for model training:

### 1. Preprocessing for Model Training (`train_preprocessing`)

The first step in model training is preprocessing, which computes clone-specific cell fractions (CFs) and generates pairwise CF plots. Pairwise CF plots can be used to select a pair of clones for model training. 

### 2.Generating Training Labels (`train_gen_labels`)

The second step involves generating the training labels needed for model training. These labels are used to guide the model during the training process.

- `train_gen_labels`: This step assigns labels to the data based on predefined criteria, preparing the dataset for the next phase.

### 3. Extract Features (`extract_features`)

After preprocessing and label generation, features need to be extracted from the data. Refer to the [extract_features documentation](#extract_features) for details on this step.

### 4. Train Model (`train_model`)

The final step is to train the model using the extracted features and training labels. This is the core step in model development where the preprocessed data is fed into the model for training.

More detailed documentation for each step is provided below.



### Train Preprocessing (`train_preprocessing`)

Preprocessing computes variant read counts and clone-specific cell fractions (CCFs), and generates pairwise CCF plots.

#### Usage

```bash
python src/main.py train_preprocessing {maf} {signals_dir} {output_dir} {bam_dirs} [--cores ncores]
```

#### Positional arguments

- `maf`: MAF format file containing candidate variants
- `signals_dir`: The output directory for signals
- `output_dir`: Output directory for results
- `bam_dirs`: List of BAM directories (as output by the ISABL app `merge_bams`)

#### Optional arguments

- `--cores`: Number of workers to use for parallelization. By default, all available cores will be used.

#### Output

The `train_preprocessing` step will output the following files:

- `{output_dir}/var_counts.tsv`: Read counts for variant and reference alleles per clone
- `{output_dir}/clone_ccfs.pdf`: Pairwise plots of clone CCFs

---

### Train Gen Labels (`train_gen_labels`)

The `train_gen_labels` step classifies variants into different clones based on the read counts generated during preprocessing.

#### Usage

```bash
python src/main.py train_gen_labels {input_file} {output_dir} {clone1} {clone2} [--cores ncores]
```

#### Positional arguments

- `input_file`: `var_counts.tsv` file from the `train_preprocessing` step
- `output_dir`: Output directory
- `clone1`: Selected clone for training label generation
- `clone2`: Selected clone for training label generation

#### Optional arguments

- `--cores`: Number of workers to use for parallelization. By default, all available cores will be used.

#### Output

The `train_gen_labels` step will output the following files:

- `{output_dir}/assignments.tsv`: TSV file with variant labels from the training label generation
- `{output_dir}/ccfs_labeled.pdf`: Labeled pairwise plot for selected CCFs with the inferred classification

---

### Train Classifier (`train_model`)

This step trains a model using the features extracted from variants and the classifications generated by the `train_gen_labels` step.

#### Usage

```bash
python src/main.py train_model {filelist} {output_dir}
```

#### Positional arguments

- `filelist`: A list of files containing training data. Each line corresponds to one sample or individual, and should contain the features file (output by `extract_features`) and assignment file (output by `train_gen_labels`) separated by a tab. This file has no header.
- `output_dir`: Output directory for the trained model.

#### Output

The `train_model` step will output the following files:

- `{output_dir}/model.pkl`: The trained model file
- `{output_dir}/scaler.pkl`: The data scaler file for transforming future data inputs